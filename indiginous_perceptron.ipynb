{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indiginous_perceptron.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/lrdshiva/home_made-multi_class_perceptron/blob/master/indiginous_perceptron.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DE_EbGObapu3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perceptron\n",
        "###by Amarnath De\n",
        "\n",
        "\n",
        "\n",
        "*   **What is a perceptron?**\n",
        "        A Perceptron in a Linear Binary Classifier that trains itself through supervised learning mechanism and classifies  data into 2 groups (for single class perceptron) and multiple groups (for multi class perceptron). \n",
        "\n",
        "* **why perceptron?**\n",
        "      Just like a biological neuron has dendrites to receive signals, a cell body to process them, and an axon to send signals out to other neurons, the artificial neuron (or perceptron) has a number of input channels, a processing stage, and one output that can fan out to multiple other artificial neurons. Although very primitive in aproach but it was the first step towards neural network. Without this the exisitance of todays deep neural net, resnet, et would have been impossible.\n",
        "      \n",
        "      Here is a link to the paper by F. Rosenblatt in the year 1958:\n",
        "      \n",
        "     http://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf\n",
        "     \n",
        "![alt text](https://appliedgo.net/media/perceptron/neuron.png)\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*n6sJ4yZQzwKL9wnF5wnVNg.png)\n",
        "\n",
        "      \n",
        "* **Steps for operation:**\n",
        "\n",
        "      1. Each input gets scaled up or down.\n",
        "      When a signal comes in, it gets multiplied by a weight value that is assigned to this particular input. That is, if a neuron has three inputs, then it has three weights that can be adjusted individually. During the learning phase, the neural network can adjust the weights based on the error of the last test result.\n",
        "      \n",
        "      2. All signals are summed up\n",
        "      In the next step, the modified input signals are summed up to a single value. In this step, an offset is also added to the sum. This offset is called bias. The neural network also adjusts the bias during the learning phase. This is where the magic happens! At the start, all the neurons have random weights and random biases. After each learning iteration, weights and biases are gradually shifted so that the next result is a bit closer to the desired output. This way, the neural network gradually moves towards a state where the desired patterns are “learned”.\n",
        "      \n",
        "      3. Activation\n",
        "      Finally, the result of the neuron’s calculation is turned into an output signal. This is done by feeding the result to an activation function (also called transfer function).\n",
        "      \n",
        "      \n",
        "\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*xsR57_PO8U7PB_ItLslLmA.png)\n",
        "\n",
        "* **Steps of Learning process:**\n",
        "    1. Initialize the weights and the threshold. Weights may be initialized to 0 or to a small random value. In the example below, we use 0.\n",
        "    2. For each example j in our training set D, perform the following steps over the input Xj and desired output dj.\n",
        "    \n",
        "        a. Calculate the actual output:\n",
        "\n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/8e2650d5fbcec4f1b38ada11b50a95014aefbd6b)\n",
        "\n",
        "         b.Update the weights:\n",
        "      \n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/57cd4d46c1a546c97ed106d62df828a0cdb91242)\n",
        "\n",
        "          3. For offline learning, the second step may be repeated until the iteration error \n",
        "          \n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/52d6809b0682721f6f29485e14003f97dccf0e46)\n",
        "          \n",
        "          is less than a user-specified error threshold \n",
        " ![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/a223c880b0ce3da8f64ee33c4f0010beee400b1a) , or a predetermined number of iterations have been completed, where s is again the size of the sample set.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###Below I have made a class called Perceptron  which is capable of multi class classification along with explanation. After that i have trained the model in a simple dataset, MNIST data set and iris data set.###\n",
        "\n",
        "\n",
        "For futher understanding  watch these videos:\n",
        "\n",
        "\n",
        "\n",
        "1.   https://www.youtube.com/watch?v=uXt8qF2Zzfo\n",
        "2.   https://www.youtube.com/watch?v=5g0TPrxKK6o&t=396s\n",
        "3.   https://www.youtube.com/watch?v=VQ1O-pSPX20\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sQofeQQygIot",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Perceptron class"
      ]
    },
    {
      "metadata": {
        "id": "jK0DXIXxgIlk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "r3CANO7sMhtv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class perceptron:\n",
        "  \n",
        "  def __init__(self,alpha=0.001,iteration=100):\n",
        "    \n",
        "    self.alpha=alpha\n",
        "    self.iteration=iteration\n",
        "   \n",
        "  def train(self, X, y):\n",
        "    \n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    \n",
        "    example,feature = X.shape  # n = examples , f = feature\n",
        "    unique_label = np.unique(y, axis=0)     \n",
        "    m = unique_label.shape[0]# number of unique feature = number of perceptron:\n",
        "    \n",
        "    new_X = np.ones((example , feature + 1))   # n x (f + 1) For including bias\n",
        "    new_X[:,1:] = X\n",
        "# the above step is used to perform the operation of weight and bias together\n",
        "  \n",
        "    self.weight = (np.random.random_sample((m,feature + 1)))  # m x (f + 1)\n",
        "    \n",
        "    #label tag \n",
        "    unique = np.unique(y)\n",
        "    self.unique = unique   #stores the unique elements in array\n",
        "    label_y = self.tag(y) # n x m\n",
        "    \n",
        "    x = np.zeros((1,feature+1))\n",
        "    T = np.zeros((1,m))\n",
        "    \n",
        "    # training process begins here.\n",
        "    for j in range(0,self.iteration):\n",
        "      \n",
        "      for i in range(0,example):\n",
        "      \n",
        "        x = new_X[i,:] # 1 x (f + 1)\n",
        "        x = x.reshape(1,feature + 1)  # <----VERY IMPORTANT STEP\n",
        "       \n",
        "        T = label_y[i,:] # 1 x m\n",
        "        T = T.reshape(m,1)            # <----VERY IMPORTANT STEP\n",
        "        \n",
        "        y = self.step(np.dot( self.weight , np.transpose(x))) # m x 1\n",
        "        y = y.reshape(m,1)            # <----VERY IMPORTANT STEP\n",
        "        \n",
        "        \n",
        "        e = np.subtract( T , y )\n",
        "        dw = self.alpha*( np.dot( e , x )) # m x (f + 1)\n",
        "        self.weight = np.add(self.weight,dw)\n",
        "        \n",
        "        \n",
        "    print(\"training complete, new weight = \\n\", self.weight )\n",
        "      \n",
        " \n",
        "  def predict(self,x):\n",
        "    \n",
        "    example,feature = x.shape  # n = example , f = feature\n",
        "    new_x = np.ones((example , feature + 1))   # n x (f + 1)\n",
        "    new_x[:,1:] = x\n",
        "    \n",
        "    y = (np.dot( new_x ,np.transpose(self.weight))) # n x m\n",
        "    tags = self.step(y)\n",
        "    \n",
        "    \n",
        "    return self.match(tags)\n",
        "    \n",
        "    \n",
        "  def match(self,tags):  #This function needs to be improved for lower O\n",
        "    n,m = tags.shape\n",
        "    \n",
        "    label = np.zeros((n,1))\n",
        "    for i in range(0,n):\n",
        "        count = 0\n",
        "        pos = 0\n",
        "        for j in range(0,m):\n",
        "            if tags[i,j] != 0:\n",
        "                count+=1\n",
        "                pos = j        \n",
        "        if count >1:\n",
        "            label[i] = None\n",
        "        if count == 1:\n",
        "            label[i] = self.unique[pos]\n",
        "        else:\n",
        "            label[i] = None \n",
        "            \n",
        "    return label \n",
        "      \n",
        "   \n",
        "    \n",
        "  def tag(self,y): \n",
        "    self.y = y\n",
        "    l = self.unique.shape[0]\n",
        "    label_y = np.zeros((y.shape[0],l))\n",
        "    \n",
        "    I = np.identity(l)\n",
        "        \n",
        "    \n",
        "    for i in range(0,self.unique.shape[0]):\n",
        "      \n",
        "        label_y[np.argwhere(y==self.unique[i])] = I[i]\n",
        "       \n",
        "    return label_y\n",
        "  \n",
        "  \n",
        "  def step(self, wx):\n",
        "    \n",
        "    return (wx>0)*1\n",
        "    \n",
        "  def score(self, test , pred) :\n",
        "    if (test.shape!=pred.shape):\n",
        "      print(\" mismatch in length\")\n",
        "      return\n",
        "    correct = 0\n",
        "    multiple = 0\n",
        "    total = test.shape[0]\n",
        "\n",
        "    for t,p in zip(test,pred):\n",
        "      if t==p:\n",
        "        correct+=1\n",
        "      elif p==None:\n",
        "        multiple+=1\n",
        "    accuracy =float((correct/total)*100)\n",
        "    print (\"score of the model:\")\n",
        "    print(\"total = \",total)\n",
        "    print(\"correct = \", correct)\n",
        "    print(\"multiple classification = \", multiple)\n",
        "    print(\"wrong = \", (total-correct))\n",
        "    print(\"accurcy = \",accuracy)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tND8xVfHmhbs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**parameters:**: alpha = 0.001(default), iteration = 100(default)\n",
        "\n",
        "call:\n",
        "\n",
        "* self.weight to get weights of the trained model\n",
        "\n",
        "* self.unique to get the unique labels\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NGFXNs_RgSsh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Perceptron using simple dataset"
      ]
    },
    {
      "metadata": {
        "id": "IkXivw2cXwO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "57c3dcd2-e0f5-4479-bdf3-8207e1ff0022"
      },
      "cell_type": "code",
      "source": [
        "x= [[1,1],\n",
        "    [1,2],\n",
        "    [2,1],\n",
        "    [2,2],\n",
        "    [3,1],\n",
        "    [3,2],\n",
        "    [8,7],\n",
        "    [8,8],\n",
        "    [9,7],\n",
        "    [9,8],\n",
        "    [10,7],\n",
        "    [10,8]]\n",
        "\n",
        "x_test = [[-1,-1],\n",
        "          [-1,-2],\n",
        "          [-2,-1],\n",
        "          [-2,-2],\n",
        "          [-3,-1],\n",
        "          [-3,-2],\n",
        "          [8,7],\n",
        "          [8,8],\n",
        "          [9,7],\n",
        "          [9,8],\n",
        "          [20,20],\n",
        "          [10,8]]\n",
        "\n",
        "y = [[1],[1],[1],[1],[1],[1],[0],[0],[0],[0],[0],[0]]\n",
        "\n",
        "p = perceptron(alpha=0.01,iteration=100)\n",
        "\n",
        "p.train(np.asarray(x),np.asarray(y))\n",
        "\n",
        "label = p.predict(np.asarray(x_test))\n",
        "\n",
        "print(\"predicted label :\\n\",label)\n",
        "\n",
        "p.score(np.asarray(y),label)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training complete, new weight = \n",
            " [[-0.24352135  0.06530109 -0.03256824]\n",
            " [ 0.80709938 -0.07486051 -0.07728969]]\n",
            "predicted label :\n",
            " [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "score of the model:\n",
            "total =  12\n",
            "correct =  12\n",
            "multiple classification =  0\n",
            "wrong =  0\n",
            "accurcy =  100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oKCZAs_sgoHZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training perceptron in MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "sI68M4nVY2H6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DLf82u2GR3Pg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following code enables us to transfer data directly from our google drive account.\n",
        "\n",
        "Visit https://pythonhosted.org/PyDrive/ for details"
      ]
    },
    {
      "metadata": {
        "id": "WJ7acBKWY6FL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQvBhGaPSGzY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports from drive account and be sure to get the id of the shareable link.\n",
        "\n",
        "I downloaded the dataset in csv format from the following link and uploaded in your drive\n",
        "####link :https://pjreddie.com/projects/mnist-in-csv/"
      ]
    },
    {
      "metadata": {
        "id": "uBdIykfkZOZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = drive.CreateFile({'id':'1L6yemQMJWFM3wvsPPlk5GQMu-LxmhI2O'}) \n",
        "\n",
        "test_df = drive.CreateFile({'id':'1oAki5WrvXajt0iaBHshx1ShKRTixgD7y'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HSblW20kZRfZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df.GetContentFile('mnist_train.csv')\n",
        "test_df.GetContentFile('mnist_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwF5WIwCZSfZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = np.genfromtxt('mnist_train.csv', delimiter = ',')\n",
        "test = np.genfromtxt('mnist_test.csv', delimiter = ',')\n",
        "\n",
        "# extract the X part and y part of data set\n",
        "# as the first col is label data\n",
        "\n",
        "train_X = train[:,1:] \n",
        "test_X = test[:,1:]\n",
        "\n",
        "train_y=train[:,0]\n",
        "test_y=test[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ONoa0jW-ZVQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "47d3d011-95f4-4cfd-9171-71a1e05df42b"
      },
      "cell_type": "code",
      "source": [
        "p1 = perceptron(alpha=0.1,iteration=21)\n",
        "p1.train(train_X,train_y)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training complete, new weight = \n",
            " [[-1.90207507e+02  3.27512515e-01  3.56345635e-01 ...  4.41578805e-01\n",
            "   5.09951385e-01  7.70930986e-01]\n",
            " [-2.84054780e+01  7.95494894e-01  8.70733973e-03 ...  4.46012856e-01\n",
            "   9.71186630e-02  3.37486192e-01]\n",
            " [-1.98983313e+02  8.58778720e-01  8.42654426e-01 ...  1.38736199e-01\n",
            "   4.50506569e-01  8.87607691e-02]\n",
            " ...\n",
            " [-2.75478606e+01  9.10420320e-01  4.42140299e-02 ...  3.91830369e-01\n",
            "   7.03065188e-01  8.56307852e-01]\n",
            " [-1.37549568e+03  8.26953884e-01  1.68852378e-01 ...  1.41056237e-01\n",
            "   8.46947097e-01  3.98707749e-01]\n",
            " [-5.58829801e+02  9.47331853e-01  3.11324729e-01 ...  6.35004768e-02\n",
            "   3.72117049e-01  4.90145145e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kq7gS4LWZfHT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label = p1.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IIho_Ux2jDJm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "4074859a-65b6-4295-d02b-63978214df93"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# convert it to 28X28 format to represent it in image\n",
        "img_set = np.zeros((test.shape[0],28,28))\n",
        "img_set= test_X.reshape((-1,28,28))\n",
        "plt.imshow(img_set[0,:,:])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff637ce1ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7+fkgQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff5e92740f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UgkgWa-dZjmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7069faf7-a1cc-4f30-c911-0b85728eb173"
      },
      "cell_type": "code",
      "source": [
        "test_y = test_y.reshape(-1,1)\n",
        "test_y.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "fObvMxRIZn-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9b7ffaae-6fd0-4e6a-ff37-e2fcd847c785"
      },
      "cell_type": "code",
      "source": [
        "p1.score(test_y,label)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score of the model:\n",
            "total =  10000\n",
            "correct =  7006\n",
            "multiple classification =  0\n",
            "wrong =  2994\n",
            "accurcy =  70.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lxj8QGA1keMr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vary the learning rate and number of itterations to analize the best score .."
      ]
    },
    {
      "metadata": {
        "id": "GUpH23Vyg2OM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training perceptron using iris data"
      ]
    },
    {
      "metadata": {
        "id": "wKy7HA2kZo5P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris_data = datasets.load_iris()\n",
        "X = iris_data.data\n",
        "y = iris_data.target\n",
        "\n",
        "p2 = perceptron(alpha=0.001,iteration=120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1bwOTJQZtvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cf2f6fe0-0bdf-4714-f8b1-4dfcc613cb54"
      },
      "cell_type": "code",
      "source": [
        "p2.train(X,y)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training complete, new weight = \n",
            " [[ 0.03975068 -0.11752674  0.22996188 -0.02023275 -0.02492032]\n",
            " [ 0.23324344 -0.00467019 -0.08103285  0.02122344 -0.1167844 ]\n",
            " [ 0.40202337 -0.20605297 -0.39760706  0.20311932  0.75071223]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XfrQNxihZran",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f486f735-31cb-439a-a08f-a75a11df6445"
      },
      "cell_type": "code",
      "source": [
        "label=p2.predict(X)\n",
        "p2.score(y.reshape(-1,1),label)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score of the model:\n",
            "total =  150\n",
            "correct =  99\n",
            "multiple classification =  0\n",
            "wrong =  51\n",
            "accurcy =  66.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nMKcbeUxg_Nf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###**Note** :  As you can see that the predictions are not upto the mark for iris data. But if optimized it will definitly perform. But one limitation of perceptron is that the dataset has to be linearly seperable. as seen in this graph below###\n",
        "\n",
        "![alt text](https://i.stack.imgur.com/Ae6qa.png)\n"
        
        ]
    }
  ]
}
